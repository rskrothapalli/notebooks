{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Leveraging Tools in LangChain: Building a Smart Kangala Care Assistant'\n",
        "author: Ravi Sankar Krothapalli\n",
        "date: '2025-03-05'\n",
        "toc: true\n",
        "format:\n",
        "  html:\n",
        "    html-math-method: katex\n",
        "    code-tools: false\n",
        "    self-contained: true\n",
        "execute:\n",
        "  enabled: true\n",
        "  warning: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "## Introducing LangChain Tools and Agents\n",
        "\n",
        "This tutorial will guide you in building a smart Kangala care assistant using LangChain. The assistant offers care instructions for Kangalas, imaginary creatures, based on current weather conditions. In this tutorial, we will explore the fascinating area of tools and agents.\n",
        "\n",
        "**Tools**\n",
        "\n",
        "Tools are useful helpers designed to perform specific tasks. They can retrieve data, process information, or interact with other applications and external APIs. Each tool is built to accept certain inputs and provide results in a clear format.\n",
        "\n",
        "**Agents**\n",
        "\n",
        "Agents manage information flow and decision-making. They utilize tools to collect data, process inputs, and generate responses. Agents can be tailored with specific prompts and logic for various tasks.\n",
        "\n",
        "### Setup the environment\n",
        "\n",
        "::: callout-note\n",
        "Install necessary libraries by downloading the [reqirements.txt](https://github.com/rskrothapalli/notebooks/blob/main/llm_tutorial_requirements.txt) file located here\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from rich import print\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if loading_envs := load_dotenv():\n",
        "    print(\"Loaded environment variables\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the Chat Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "kangala_care_assistant_model = init_chat_model(\n",
        "    \"gpt-3.5-turbo\", model_provider=\"openai\", temperature=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define input schemas for your tools\n",
        "\n",
        "This input schemas are necessary to ensure data is validated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class WeatherInput(BaseModel):\n",
        "    location: str = Field(description=\"Location to check weather\")\n",
        "\n",
        "\n",
        "class KangalaInfoInput(BaseModel):\n",
        "    temperature: int = Field(description=\"Current temperature\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrieve Weather Data\n",
        "\n",
        "Create a tool to retrieve the current weather data based on the location using the OpenWeatherMap API.\n",
        "\n",
        "To access the OpenWeatherMap API, you need to sign up for an [OpenWeatherMap](https://openweathermap.org/api) Account\n",
        "\n",
        "**Use of `StructuredTool`**\n",
        "\n",
        "Structured tools use schemas to define the expected inputs and outputs. This ensures that the data passed to and from the tool is well-structured and validated, reducing the chances of errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import os\n",
        "from typing import Dict, Any\n",
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "# Get the OpenWeatherMap API key from environment variables\n",
        "api_key = os.getenv('OPENWEATHERMAP_API_KEY')\n",
        "\n",
        "\n",
        "def get_current_time_weather(location: str) -> Dict[str, Any]:\n",
        "    # Construct the API URL\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}\"\n",
        "\n",
        "    # Make the API request\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\n",
        "            f\"Error fetching data from OpenWeatherMap API: {response.status_code}\")\n",
        "\n",
        "    # Parse the JSON response\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract the timezone offset from the response\n",
        "    timezone_offset = data['timezone']\n",
        "\n",
        "    # Extract and convert the temperature from Kelvin to Fahrenheit\n",
        "    temp_at_loc = data['main']['temp']\n",
        "    temp_at_loc = round(\n",
        "        (temp_at_loc - 273.15) * 9/5 + 32, 2)\n",
        "\n",
        "    # Calculate the current time based on the timezone offset\n",
        "    current_time = datetime.now(timezone.utc) + \\\n",
        "        timedelta(seconds=timezone_offset)\n",
        "\n",
        "    return {\n",
        "        \"temperature\": int(temp_at_loc)\n",
        "    }\n",
        "\n",
        "\n",
        "# Create a structured tool for retrieving current time and weather\n",
        "current_time_weather_tool = StructuredTool.from_function(\n",
        "    func=get_current_time_weather,\n",
        "    name=\"CurrentTimeWeather\",\n",
        "    description=\"Retrieves current time and weather for a given location\",\n",
        "    args_schema=WeatherInput\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Vector Database for Kangala Information\n",
        "\n",
        "Vector stores are specialized databases that index and retrieve information based on vector representations, capturing the semantic meaning of data. For more information on embeddings, refer to this [section in part 1](https://www.arraysoflight.com/langchain_tutorial_p1.html#simple-rag-application) of this series\n",
        "\n",
        "`InMemoryVectorStore` is a simple in-memory vector store especially useful for small datasets and quick prototyping.\n",
        "\n",
        "Other popular vector stores include:\n",
        "\n",
        "-   FAISS: Known for high performance and scalability.\n",
        "\n",
        "-   Chroma: Easy to use for small to medium datasets.\n",
        "\n",
        "-   Pinecone: A managed service offering high performance and scalability.\n",
        "\n",
        "-   LanceDB: Balances performance and ease of use.\n",
        "\n",
        "-   Weaviate: An open-source and highly extensible vector search engine.\n",
        "\n",
        "-   pgvector: An open-source extension for PostgreSQL that adds support for vector operations and similarity searches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Sample Kangala fun facts and care information\n",
        "kangala_docs = [\n",
        "    \"Kagalas need to be fed every 4 hours when the temperature is below 60°F.\"\n",
        "    \"Kagalas need to be fed every 6 hours when the temperature is between 60°F-75°F. \"\n",
        "    \"Kagalas need to be fed every 8 hours when the temperature is above 75°F.\",\n",
        "    \"Kangalas' fur changes to a darker shade below 50°F, indicating that it is too cold for them to survive hence, they need to stay indoors at a comfortable temperature. \"\n",
        "    \"Kangalas' fur changes to a lighter shade above 80°F, indicating they are starting to get overheated hence, they need to stay indoors at a comfortable temperature.\",\n",
        "    \"When temperatures exceed 80°F, Kangalas need to be misted with water every 2 hours to prevent overheating and need plenty of water.\",\n",
        "    \"Kangalas are more vocal and active at temperatures between 65°F and 75°F, which is their optimal comfort range.\"\n",
        "]\n",
        "\n",
        "# Create vector database for Kangala information\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20,\n",
        "    separators=[\"\\n\", \".\", \" \"])\n",
        "texts = text_splitter.create_documents(kangala_docs)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "kangala_db = InMemoryVectorStore.from_documents(texts, embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Temperature-Aware Retriever Tool\n",
        "\n",
        "The code is an oversimplification of the retriever tool where we extract relevent documents given the temperature of a location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.tools import StructuredTool\n",
        "\n",
        "\n",
        "class TemperatureAwareRetriever:\n",
        "    def __init__(self, vector_store, embeddings):\n",
        "        self.vector_store = vector_store\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "    def retrieve_with_temperature(self, temperature):\n",
        "        # Modify the query to include temperature context\n",
        "        enhanced_query = f\"Temperature is {temperature}°F. Retrieve specific care documents\"\n",
        "\n",
        "        # Perform similarity search with a higher k value\n",
        "        docs = self.vector_store.similarity_search(enhanced_query, k=30)\n",
        "\n",
        "        # Filter documents based on temperature\n",
        "        filtered_docs = [\n",
        "            doc for doc in docs\n",
        "            if self._is_relevant_to_temperature(doc.page_content, temperature)\n",
        "        ]\n",
        "\n",
        "        # Return filtered docs if not empty, otherwise return original docs\n",
        "        return filtered_docs or docs\n",
        "\n",
        "    def _is_relevant_to_temperature(self, text, temperature):\n",
        "        # Define temperature ranges with their corresponding descriptors\n",
        "        temperature_ranges = [\n",
        "            ((0, 50), [\"below 50°F\", \"under 50°F\",\n",
        "             \"less than 50°F\", \"below 60°F\"]),\n",
        "            ((50, 60), [\"between 50°F-60°F\", \"50°F to 60°F\",\n",
        "             \"around 50°F\", \"between 50°F and 60°F\", \"below 60°F\"]),\n",
        "            ((60, 75), [\"between 60°F-75°F\", \"60°F to 75°F\",\n",
        "             \"around 70°F\", \"below 75°F\", \"above 60°F\"]),\n",
        "            ((75, 80), [\"between 75°F-80°F\",\n",
        "             \"75°F to 80°F\", \"around 75°F\", \"above 75°F\"]),\n",
        "            ((80, float('inf')), [\"above 80°F\",\n",
        "             \"over 80°F\", \"exceed 80°F\", \"above 75°F\", ])\n",
        "        ]\n",
        "\n",
        "        # Convert temperature to float for comparison\n",
        "        temp = float(temperature)\n",
        "\n",
        "        # Check if temperature falls in the range\n",
        "        for (low, high), range_descriptors in temperature_ranges:\n",
        "            if low <= temp < high:\n",
        "                # Check if any of the range descriptors are in the text\n",
        "                return any(desc in text for desc in range_descriptors)\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "# Create temperature-aware retriever\n",
        "temp_aware_retriever = TemperatureAwareRetriever(kangala_db, embeddings)\n",
        "\n",
        "# Create a tool that accepts temperature\n",
        "\n",
        "\n",
        "def kangala_info_with_temperature(temperature=70):\n",
        "    # Retrieve documents relevant to the query and temperature\n",
        "    docs = temp_aware_retriever.retrieve_with_temperature(temperature)\n",
        "\n",
        "    # Convert retrieved documents to readable text\n",
        "    return \"\\n\".join([doc.page_content for doc in docs]) if docs else \"No specific information found.\"\n",
        "\n",
        "\n",
        "# Create a structured tool for retrieving current time and weather\n",
        "kangala_info_tool = StructuredTool(\n",
        "    name=\"KangalaInfo\",\n",
        "    description=\"Retrieves Kangala care information based on current temperature and query\",\n",
        "    func=kangala_info_with_temperature,\n",
        "    args_schema=KangalaInfoInput\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the Agent & Custom Agent Executor\n",
        "\n",
        "The agent below is designed to provide care instructions for Kangalas based on the current weather conditions.\n",
        "\n",
        "The agent uses the current_time_weather_tool to retrieve weather data and the kangala_info_tool to provide care information.\n",
        "\n",
        "The agent defined here is a `ReAct` agent.\n",
        "\n",
        "#### Introducing ReAct Agent\n",
        "\n",
        "The ReAct (Reasoning and Acting) agent in LangChain is designed to handle complex tasks by reasoning through the steps required and taking appropriate actions. It uses a structured approach to break down tasks into smaller, manageable actions, making it easier to handle multi-step processes.\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "-   **Reasoning**: The agent thinks through the steps needed to achieve the goal.\n",
        "\n",
        "-   **Acting**: It performs actions based on the reasoning, using available tools.\n",
        "\n",
        "-   **Iterative Process**: The agent can iterate through multiple Thought/Action/Observation cycles to refine its approach and reach the final answer.\n",
        "\n",
        "**Example Workflow:**\n",
        "\n",
        "1.  **Question**: The input question the agent must answer.\n",
        "\n",
        "2.  **Thought**: The agent thinks about what to do next.\n",
        "\n",
        "3.  **Action**: The agent decides on an action to take.\n",
        "\n",
        "4.  **Action Input**: The input to the action.\n",
        "\n",
        "5.  **Observation**: The result of the action.\n",
        "\n",
        "6.  **Final Answer**: The final answer to the original question.\n",
        "\n",
        "`CustomAgentExecutor` is used to create custom agent executor to handle tool chaining."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from rich.markdown import Markdown\n",
        "\n",
        "# Ensure you have tool names\n",
        "tool_names = [tool.name for tool in [\n",
        "    current_time_weather_tool, kangala_info_tool]]\n",
        "\n",
        "# Create a custom prompt template with required variables\n",
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"\"\"You are a specialized Kangala care assistant.\n",
        "Kangalas are imaginary animals whose behavior and care requirements change based on weather conditions and time of day. \n",
        "\n",
        "TOOLS:\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action (IMPORTANT: use ONLY the numeric float value for temperature)\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question. Provide current temperature. Print each sentence in a new line and use friendly and fun tone. Use the format below:\n",
        "                            **The current temperature in <location> is <temperature> degrees Fahrenheit.** \\n\n",
        "                            - <care information 1> \\n\n",
        "                            - <care information 2> \\n\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\"\"\")\n",
        "\n",
        "# Create a custom tool chain function\n",
        "\n",
        "\n",
        "def prepare_kangala_info_input(input_dict):\n",
        "    # First, get the weather information\n",
        "    weather_result = current_time_weather_tool.invoke(input_dict[\"input\"])\n",
        "\n",
        "    # Extract the temperature as a float\n",
        "    temperature = float(weather_result.get('temperature'))\n",
        "\n",
        "    return {\"temperature\": temperature}\n",
        "\n",
        "\n",
        "# Create the agent with the correct parameters\n",
        "agent = create_react_agent(\n",
        "    kangala_care_assistant_model,\n",
        "    [current_time_weather_tool, kangala_info_tool],\n",
        "    prompt=prompt_template\n",
        ")\n",
        "\n",
        "# Create a custom agent executor that handles tool chaining\n",
        "class CustomAgentExecutor(AgentExecutor):\n",
        "    def invoke(self, input_dict, config=None):\n",
        "        # Prepare Kangala info input before invoking the agent\n",
        "        kangala_input = prepare_kangala_info_input(input_dict)\n",
        "\n",
        "        # Modify the input to include prepared Kangala info\n",
        "        input_dict['kangala_input'] = kangala_input\n",
        "\n",
        "        # Call the parent class's invoke method\n",
        "        return super().invoke(input_dict, config)\n",
        "\n",
        "\n",
        "# Create the agent executor\n",
        "agent_executor = CustomAgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=[current_time_weather_tool, kangala_info_tool],\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Invoke Agent Executor and Evaluate Model Responses\n",
        "\n",
        "The response provides detailed logs of each step in the agent's reasoning and actions.\n",
        "\n",
        "This includes the inputs, outputs, and intermediate thoughts, making it easier to debug and understand the agent's behavior.\n",
        "\n",
        "This detailed logging is enabled by setting the `verbose` argument to True in the `CustomAgentExecutor`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Invoke the agent\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": 'London, UK',\n",
        "    \"chat_history\": []  # Empty chat history for first interaction\n",
        "})\n",
        "\n",
        "print(Markdown(response[\"output\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Invoke the agent\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": 'Hyderabad, India',\n",
        "    \"chat_history\": []  # Empty chat history for first interaction\n",
        "})\n",
        "\n",
        "print(Markdown(response[\"output\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Invoke the agent\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": 'Singapore, Singapore',\n",
        "    \"chat_history\": []  # Empty chat history for first interaction\n",
        "})\n",
        "\n",
        "print(Markdown(response[\"output\"]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/KROTHRX2/Library/Caches/pypoetry/virtualenvs/databricks-debug-Tkkk92Ig-py3.11/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}